# Live Streaming
How does live streaming work on YouTube and Twitch? How do these popular live streaming platforms deliver video content from the streamer's computer to the viewer's device, or the so-called "glass-to-glass" latency, that is measured in low tends of seconds or faster? 

Live Streaming is challenging because the video content is sent over the internet in near real-time. Video processing is computer-intensive. Sending a large volume of video contents over the internet takes time. These factors make live streaming challenging. 

### Streamer, Encoder
Let's take a look at how a video stream goes from the streamer to the viewers. First, the steamer starts their stream. The source could be any video and audio source wired up to an encoder, something like the popular open-source OBS software. Some popular platforms like YouTube provide easy-to-use software to stream from a browser with a webcam, or directly from a mobile phone camera. The job of the encoder is to package the video stream and send it in a transport protocol that the live streaming platform can receive for future processing. The most popular transport protocol is called RTMP (Real-time Messaging Protocol). RTMP is a TCP-based protocol. It started out a long time ago as the video streaming protocol for Adobe Flash. The encoders can all speak RTMP, or its secure variant called RTMPS. There is a new protocol called SRT (Secure Reliable Transport) that could start to replace RTMP. SRT is UDP-based and it promises lower latency and better resilience to poor network conditions. However, most of the popular streaming platforms do not yet support SRT. To provide best upload condition for the steamer, most of live streaming platforms provide point-of-presence servers worldwide. The streamer connects to a point-of=presence server closet to them. This usually happens automatically with either DNS latency based routing or an anycast network. Once the stream reaches the point-of-presence server, it is transmitted over a fast and reliable backbone network to the platform for future processing. 

### Platform
At the platform, the main goal of this additional processing it to offer the video stream in different qualities and bit-rates. Modem video players automatically choose the best video resolution and bit rate based on the quality of the viewer's internet connection and can adjust on the fly by requesting different bit rates as the network condition changes. This is called adaptive bitrate streaming. The exact processing steps vary by platform and the output streaming formats. In general, they fall into the following categories. 

First, the incoming video stream is transcoded to different resolutions and bit-rates, basically different quality levels for the video. The transcoded stream is divided into smaller video segments a few seconds in length. This process is called segmentation. Transcoding is compute-intensive. The input stream is usually transcoded to different formats in parallel, requiring massive computer power.

Next, the collections of video segments from the transcoding process are packaged into different live streaming formats that video players can understand. The most common live-streaming format is HLS, or HTTP Live Streaming. HLS was invented by Apple in 2009. It is the most popular streaming format to date. An HLS stream consists of a manifest file, and a series of video chunks, with each chunk containing a video segment as short as a few seconds. The manifest file is a directory to tell the video player hat all the out formats are, and where to load the video chunks over HTTP. The resulting HLS manifest and video chunks from the packaging step are cashed by the CDN. This reduces the so-called last-mile latency to the viewers. DASH (Dynamic Adaptive streaming over HTTP) is another popular streaming format. Apple devices natively do not support DASH. 

### Viewer
Finally, the video starts to arrive at the viewer's video player. The "glass-to-glass" latency of around 20 seconds is normal.There are several factors a streamer or the live streaming platform could tune to improve this latency by sacrificing various aspects of the overall video quality. Some platforms simplify this tuning process by providing a coarse knob for the streamer to choose the level of interactivity they desire. The platforms then adjust the quality of the stream based on that input. This is largely a black box from the streamer's perspective. The best thing the streamer could do is optimize their local setup for the lowest latency from the camera to the streaming platform.