# Back-Of-The-Envelope Estimation
Back-of-the-envelope math is a very useful tool in our system design toolbox. We will go over how and when to use it, and share some tips on using it effectively. Experienced developers use back-of-the-envelope math to quickly sanity-check a design. In these cases, absolute accuracy is not that important. Usually, it is good enough to get within an order of magnitude or two of the actual numbers we are looking for. For example, if the math says at our scale our web service needs to handle 1M requests per second, and each web server could only handle about 10K requests per second, we learn two things quickly: 
1. We learn that we will need a cluster of web servers, with a load balancer in front of them. 
2. We will need about 100 web servers. 

Another example is if the math shows that the database needs to handle about 10 queries per second at peak, it means that a single database server could handle the load for a while, and there is no need to consider sharding or caching for a while. Now let's go over some of the most popular numbers to estimate. The most useful by far is requests per second at the service level or queries per second at the database level. 

Let's go over the common inputs in a requests-per-second calculation. The first is DAU (Daily Active Users). This number should be easy to obtain. Sometimes, the only available number would be Monthly Active Users. In that case, estimate the DAU as a percentage of MAU. The second input is the estimate of the usage per DAU of the service we are designing for. For example, not everyone active on Twitter makes a post. Only a percentage does that. 10% - 25% seems to be reasonable. Again, it doesn't have to be exact. Getting within an order of magnitude is usually fine. The third input is a scaling factor. The usage rate for a service usually has peaks and valleys throughout the day. We need to estimate how much higher the traffic would peak compared to the average. This would reflect the estimated requests-per-second peak where the design could potentially break. For example, for a service like Google Maps, the usage rate during commute hours could be 5 times higher than average. Another example is a ride-sharing service like Uber, where weekend nights could have twice as many rides as average. 

Now, let's go over an example. We will estimate the number of tweets created per second on Twitter. Note that, these numbers are made up, and they are not official numbers from Twitter. Let's assume Twitter has 300 million MAU, and 50% of the MAU use Twitter daily. So that's about 150 million DAU. Next, we estimate that about 25% of Twitter DAU make tweets. And each one on average makes 2 tweets. That is 25% * 2 = 0.5 tweets per DAU. For the scaling factor, we estimate that most people tweet in the morning when they get up and can't wait to share what they dreamed about the night before. And that spikes the tweet traffic to twice the average when the US east coast wakes up. Now we have enough to calculate the peak tweets created per second. We have: 150 million DAU X 0.5 tweet per DAU X 2x scaling factor / 86,400 seconds in a day. That is roughly about 1,500 tweets per second. Let's go over the techniques to simplify the calculations. First, we convert all big numbers to scientific notation. Doing the math on really big numbers is very error-prone. By converting big numbers to scientific notation, part of the multiplication becomes simple addition, and division becomes subtraction: 1.5 X 10e8 * 0.5 * 2 / 10e5 = 1500.
Now with practice, we should be able to convert a large number to scientific notation in seconds. And we shold know by heart that 10^12 is trillion (TB), and when we see a number like 50TB, we should be able to convert it quickly to 5X10^1X10^12, which is 5x10^13. We are going to ignore the fact that 1KB is actually 2^10 bytes (1024 bytes). We don't need that degree of accuracy for back-of-the-envelope math.

Let's wrap up by going through one last example. We will estimate how much storage is required for storing multimedia files for tweets. We know from the previous example that there are about 150M tweets per day. Now we need an estimate on estimate on a percentage of tweets that could contain multimedia content, and how large those files are on average. With our meticulous research, we estimate that 10% of tweets contain pictures, and they are about 100KB each, and 1% of the tweets contain videos, and they are 100MB each. We further assume that the files are replicated, with 3 copies each, and that Twitter would keep the media for 5 years. Now here is the math. For storing pictures, we have the following: 150M tweets X 0.1 in pictures X 100KB/picture X 400 days/year X 5 years X 3 copies. So that turns into: 1.5*10^8 * 10^(-1) * 10^5 * 4*10^2 * 5 * 3. Again, we group the powers of tens together, 90 * 10^(8-1+5+2) = 9 * 10^15 = 9PB. For storing videos, we take yet another shortcut. Since videos on average are 100MB each while pictures are 100KB, a video is 1000 times bigger than a picture on average. Second, only 1% of tweets contain a video, while pictures appear in 10% of all the tweets. So videos are one-tenth as popular. Putting the math together, the total video storage is 1000 * 1/10 of picture storage, which is 900PB. 

In conclusion, back-of-the-envelope math is a very useful tool in our system design toolbox. Don't over-index on precision. Getting within an order of magnitude is usually enough to inform and validate our design. 